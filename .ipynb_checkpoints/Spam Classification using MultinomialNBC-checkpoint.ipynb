{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download all NLTK Packages{If already installed then skip it}\n",
    "nltk.download('pe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data\n",
    "data=pd.read_csv('SMS Spam Collection', sep='\\t', names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      "label      5572 non-null object\n",
      "message    5572 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17c58c19518>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Countplotting the labels to check for imbalanced dataset\n",
    "import seaborn as sns\n",
    "sns.countplot(x=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Stemming and Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Stemming\n",
    "ps=PorterStemmer()\n",
    "corpus=[]\n",
    "\n",
    "#Iterating over every record\n",
    "for i in range(len(data)):\n",
    "    #Using Regular Expression to remove any punctuation or special symbols from messages \n",
    "    message=re.sub('[^a-zA-Z]',' ',data['message'][i])\n",
    "    #Lowercasing the messages\n",
    "    message=message.lower()\n",
    "    #Splitting the messages into words\n",
    "    message=message.split()\n",
    "    \n",
    "    #List Comprehension to Porter Stemming and removal of stop words\n",
    "    message=[ps.stem(word) for word in message if not word in stopwords.words('english')]\n",
    "    #Joining the words back together to form sentence\n",
    "    message=' '.join(message)\n",
    "    #Appending message to corpus\n",
    "    corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
       " 'ok lar joke wif u oni',\n",
       " 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli',\n",
       " 'u dun say earli hor u c alreadi say',\n",
       " 'nah think goe usf live around though']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=2500)\n",
    "X=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting label into numerical categories\n",
    "y=pd.get_dummies(data['label'])\n",
    "y=y.iloc[:,1].values\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.9856502242152466\n",
      "\n",
      "Confusion Matrix: \n",
      "[[946   9]\n",
      " [  7 153]]\n",
      "\n",
      "Confusion Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       955\n",
      "           1       0.94      0.96      0.95       160\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1115\n",
      "   macro avg       0.97      0.97      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score, Confusion Matrix and Classification Report\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "acc=model.score(X_test,y_test)\n",
    "print('Accuracy: ')\n",
    "print(acc)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print('\\nConfusion Matrix: ')\n",
    "print(cm)\n",
    "cr=classification_report(y_test,y_pred)\n",
    "print('\\nConfusion Report: ')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Lemmatization and TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Lemmatization\n",
    "lem=WordNetLemmatizer()\n",
    "corpus=[]\n",
    "\n",
    "#Iterating over each record\n",
    "for i in range(len(data)):\n",
    "    #Using Regular Expression to remove punctuation or special symbols from messages\n",
    "    message=re.sub('[^a-zA-Z]',' ',data['message'][i])\n",
    "    #Lowercasing the messages\n",
    "    message=message.lower()\n",
    "    #Splitting the message into words\n",
    "    message=message.split()\n",
    "    \n",
    "    #List Comprehension for lemmatiztion and removing stopwords\n",
    "    message=[lem.lemmatize(word) for word in message if not word in stopwords.words('english')]\n",
    "    #Joining the words back to form sentence\n",
    "    message=' '.join(message)\n",
    "    #Appending message to corpus\n",
    "    corpus.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
       " 'ok lar joking wif u oni',\n",
       " 'free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply',\n",
       " 'u dun say early hor u c already say',\n",
       " 'nah think go usf life around though']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating TF-IDF Model\n",
    "tfidf=TfidfVectorizer(max_features=2500)\n",
    "X=tfidf.fit_transform(corpus).toarray()\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting label to numerical categories\n",
    "y=pd.get_dummies(data['label'])\n",
    "y=y.iloc[:,1].values\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model using Naive bayes classifier\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \n",
      "0.979372197309417\n",
      "\n",
      "Confusion Matrix: \n",
      "[[954   1]\n",
      " [ 22 138]]\n",
      "\n",
      "Confusion Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       955\n",
      "           1       0.99      0.86      0.92       160\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score, Confusion Matrix and Classification Report\n",
    "acc=model.score(X_test,y_test)\n",
    "print('Accuracy: ')\n",
    "print(acc)\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print('\\nConfusion Matrix: ')\n",
    "print(cm)\n",
    "cr=classification_report(y_test,y_pred)\n",
    "print('\\nConfusion Report: ')\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hey love much wait see'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the model ourself for ham\n",
    "test_message='Hey, I love you so much! Can\\'t wait to see you again.'\n",
    "#Using Lemmatization\n",
    "#Using Regular Expression to remove punctuation or special symbols from test message\n",
    "message=re.sub('[^a-zA-Z]',' ',test_message)\n",
    "#Lowercasing the message\n",
    "message=message.lower()\n",
    "#Splitting the message into words\n",
    "message=message.split()\n",
    "    \n",
    "#List Comprehension for lemmatiztion and removing stopwords\n",
    "message=[lem.lemmatize(word) for word in message if not word in stopwords.words('english')]\n",
    "#Joining the words back to form sentence\n",
    "message=' '.join(message)\n",
    "corpus.append(message)\n",
    "corpus[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating TF-IDF Model\n",
    "tfidf=TfidfVectorizer(max_features=2500)\n",
    "X=tfidf.fit_transform(corpus).toarray()\n",
    "X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting\n",
    "pred=model.predict(X[[-1]])\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
